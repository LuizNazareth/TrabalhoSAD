{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pip install imblearn\n",
    "# !pip install keras\n",
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, r2_score, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import SelectKBest, chi2, RFE, f_classif\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2023 = pd.read_csv('2023/data2023')\n",
    "data2020 = pd.read_csv('2020/data2020')\n",
    "data2016 = pd.read_csv('2016/data2016')\n",
    "data2012 = pd.read_csv('2012/data2012')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percent Insurence: Under 19 years</th>\n",
       "      <th>Percent Insurence: 19 to 64 years</th>\n",
       "      <th>Percent Insurence: 65 years and older</th>\n",
       "      <th>Kindergarten</th>\n",
       "      <th>Elementary: grade 1 to grade 4</th>\n",
       "      <th>Elementary: grade 5 to grade 8</th>\n",
       "      <th>High school: grade 9 to grade 12</th>\n",
       "      <th>College, undergraduate</th>\n",
       "      <th>Graduate, professional school</th>\n",
       "      <th>Population enrolled in college or graduate school</th>\n",
       "      <th>...</th>\n",
       "      <th>Two or more races:</th>\n",
       "      <th>Percent below poverty level: Population for whom poverty status is determined</th>\n",
       "      <th>Percent below poverty level: Less than high school graduate</th>\n",
       "      <th>Percent below poverty level: High school graduate (includes equivalency)</th>\n",
       "      <th>Percent below poverty level: Some college, associate's degree</th>\n",
       "      <th>Percent below poverty level: Bachelor's degree or higher</th>\n",
       "      <th>Percent below poverty level: Employed</th>\n",
       "      <th>Percent below poverty level: Unemployed</th>\n",
       "      <th>States</th>\n",
       "      <th>venceu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.177632</td>\n",
       "      <td>0.577689</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.485075</td>\n",
       "      <td>0.442029</td>\n",
       "      <td>0.306011</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.087459</td>\n",
       "      <td>0.161739</td>\n",
       "      <td>0.093178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037844</td>\n",
       "      <td>0.633803</td>\n",
       "      <td>0.713483</td>\n",
       "      <td>0.489051</td>\n",
       "      <td>0.662921</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.690141</td>\n",
       "      <td>0.804651</td>\n",
       "      <td>Alabama2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.822368</td>\n",
       "      <td>0.812749</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.485075</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.082508</td>\n",
       "      <td>0.151304</td>\n",
       "      <td>0.099834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027340</td>\n",
       "      <td>0.007042</td>\n",
       "      <td>0.129213</td>\n",
       "      <td>0.116788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.098592</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>Alaska2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.717131</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.186567</td>\n",
       "      <td>0.202899</td>\n",
       "      <td>0.065574</td>\n",
       "      <td>0.096154</td>\n",
       "      <td>0.067657</td>\n",
       "      <td>0.370435</td>\n",
       "      <td>0.111481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105849</td>\n",
       "      <td>0.612676</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.562044</td>\n",
       "      <td>0.528090</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.732394</td>\n",
       "      <td>0.725581</td>\n",
       "      <td>Arizona2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.296053</td>\n",
       "      <td>0.764940</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.134328</td>\n",
       "      <td>0.340580</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.185897</td>\n",
       "      <td>0.056106</td>\n",
       "      <td>0.092174</td>\n",
       "      <td>0.053245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027153</td>\n",
       "      <td>0.690141</td>\n",
       "      <td>0.662921</td>\n",
       "      <td>0.547445</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.774648</td>\n",
       "      <td>0.846512</td>\n",
       "      <td>Arkansas2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.427632</td>\n",
       "      <td>0.772908</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.328358</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.213115</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.130363</td>\n",
       "      <td>0.553043</td>\n",
       "      <td>0.188020</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.492958</td>\n",
       "      <td>0.466292</td>\n",
       "      <td>0.503650</td>\n",
       "      <td>0.528090</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.591549</td>\n",
       "      <td>0.386047</td>\n",
       "      <td>California2012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.360825</td>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.410853</td>\n",
       "      <td>0.302469</td>\n",
       "      <td>0.195584</td>\n",
       "      <td>0.386980</td>\n",
       "      <td>0.228041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125174</td>\n",
       "      <td>0.213115</td>\n",
       "      <td>0.237288</td>\n",
       "      <td>0.191083</td>\n",
       "      <td>0.189474</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.246377</td>\n",
       "      <td>Virginia2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.134021</td>\n",
       "      <td>0.260204</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.513333</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.179012</td>\n",
       "      <td>0.123028</td>\n",
       "      <td>0.273056</td>\n",
       "      <td>0.131757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165817</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.197740</td>\n",
       "      <td>0.178344</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.328502</td>\n",
       "      <td>Washington2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.144330</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.171171</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.172840</td>\n",
       "      <td>0.100946</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>0.795082</td>\n",
       "      <td>0.768362</td>\n",
       "      <td>0.452229</td>\n",
       "      <td>0.652632</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.704918</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>West Virginia2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.247423</td>\n",
       "      <td>0.188776</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.728682</td>\n",
       "      <td>0.253086</td>\n",
       "      <td>0.151420</td>\n",
       "      <td>0.339964</td>\n",
       "      <td>0.130068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057145</td>\n",
       "      <td>0.295082</td>\n",
       "      <td>0.282486</td>\n",
       "      <td>0.146497</td>\n",
       "      <td>0.231579</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.426230</td>\n",
       "      <td>0.487923</td>\n",
       "      <td>Wisconsin2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.762887</td>\n",
       "      <td>0.602041</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001798</td>\n",
       "      <td>0.278689</td>\n",
       "      <td>0.197740</td>\n",
       "      <td>0.133758</td>\n",
       "      <td>0.242105</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.487923</td>\n",
       "      <td>Wyoming2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Percent Insurence: Under 19 years  Percent Insurence: 19 to 64 years  \\\n",
       "0                            0.177632                           0.577689   \n",
       "1                            0.822368                           0.812749   \n",
       "2                            0.776316                           0.717131   \n",
       "3                            0.296053                           0.764940   \n",
       "4                            0.427632                           0.772908   \n",
       "..                                ...                                ...   \n",
       "46                           0.360825                           0.387755   \n",
       "47                           0.134021                           0.260204   \n",
       "48                           0.144330                           0.285714   \n",
       "49                           0.247423                           0.188776   \n",
       "50                           0.762887                           0.602041   \n",
       "\n",
       "    Percent Insurence: 65 years and older  Kindergarten  \\\n",
       "0                                0.055556      0.485075   \n",
       "1                                0.333333      0.485075   \n",
       "2                                0.555556      0.186567   \n",
       "3                                0.111111      0.134328   \n",
       "4                                0.833333      0.328358   \n",
       "..                                    ...           ...   \n",
       "46                               0.470588      0.560000   \n",
       "47                               0.352941      0.513333   \n",
       "48                               0.117647      0.200000   \n",
       "49                               0.117647      0.620000   \n",
       "50                               0.176471      0.233333   \n",
       "\n",
       "    Elementary: grade 1 to grade 4  Elementary: grade 5 to grade 8  \\\n",
       "0                         0.442029                        0.306011   \n",
       "1                         0.500000                        0.180328   \n",
       "2                         0.202899                        0.065574   \n",
       "3                         0.340580                        0.163934   \n",
       "4                         0.260870                        0.213115   \n",
       "..                             ...                             ...   \n",
       "46                        0.405405                        0.410853   \n",
       "47                        0.486486                        0.348837   \n",
       "48                        0.171171                        0.186047   \n",
       "49                        0.837838                        0.728682   \n",
       "50                        0.000000                        0.000000   \n",
       "\n",
       "    High school: grade 9 to grade 12  College, undergraduate  \\\n",
       "0                           0.365385                0.087459   \n",
       "1                           0.307692                0.082508   \n",
       "2                           0.096154                0.067657   \n",
       "3                           0.185897                0.056106   \n",
       "4                           0.205128                0.130363   \n",
       "..                               ...                     ...   \n",
       "46                          0.302469                0.195584   \n",
       "47                          0.179012                0.123028   \n",
       "48                          0.172840                0.100946   \n",
       "49                          0.253086                0.151420   \n",
       "50                          0.067901                0.000000   \n",
       "\n",
       "    Graduate, professional school  \\\n",
       "0                        0.161739   \n",
       "1                        0.151304   \n",
       "2                        0.370435   \n",
       "3                        0.092174   \n",
       "4                        0.553043   \n",
       "..                            ...   \n",
       "46                       0.386980   \n",
       "47                       0.273056   \n",
       "48                       0.025316   \n",
       "49                       0.339964   \n",
       "50                       0.000000   \n",
       "\n",
       "    Population enrolled in college or graduate school  ...  \\\n",
       "0                                            0.093178  ...   \n",
       "1                                            0.099834  ...   \n",
       "2                                            0.111481  ...   \n",
       "3                                            0.053245  ...   \n",
       "4                                            0.188020  ...   \n",
       "..                                                ...  ...   \n",
       "46                                           0.228041  ...   \n",
       "47                                           0.131757  ...   \n",
       "48                                           0.081081  ...   \n",
       "49                                           0.130068  ...   \n",
       "50                                           0.000000  ...   \n",
       "\n",
       "    Two or more races:  \\\n",
       "0             0.037844   \n",
       "1             0.027340   \n",
       "2             0.105849   \n",
       "3             0.027153   \n",
       "4             1.000000   \n",
       "..                 ...   \n",
       "46            0.125174   \n",
       "47            0.165817   \n",
       "48            0.008575   \n",
       "49            0.057145   \n",
       "50            0.001798   \n",
       "\n",
       "    Percent below poverty level: Population for whom poverty status is determined  \\\n",
       "0                                            0.633803                               \n",
       "1                                            0.007042                               \n",
       "2                                            0.612676                               \n",
       "3                                            0.690141                               \n",
       "4                                            0.492958                               \n",
       "..                                                ...                               \n",
       "46                                           0.213115                               \n",
       "47                                           0.229508                               \n",
       "48                                           0.795082                               \n",
       "49                                           0.295082                               \n",
       "50                                           0.278689                               \n",
       "\n",
       "    Percent below poverty level: Less than high school graduate  \\\n",
       "0                                            0.713483             \n",
       "1                                            0.129213             \n",
       "2                                            0.769663             \n",
       "3                                            0.662921             \n",
       "4                                            0.466292             \n",
       "..                                                ...             \n",
       "46                                           0.237288             \n",
       "47                                           0.197740             \n",
       "48                                           0.768362             \n",
       "49                                           0.282486             \n",
       "50                                           0.197740             \n",
       "\n",
       "    Percent below poverty level: High school graduate (includes equivalency)  \\\n",
       "0                                            0.489051                          \n",
       "1                                            0.116788                          \n",
       "2                                            0.562044                          \n",
       "3                                            0.547445                          \n",
       "4                                            0.503650                          \n",
       "..                                                ...                          \n",
       "46                                           0.191083                          \n",
       "47                                           0.178344                          \n",
       "48                                           0.452229                          \n",
       "49                                           0.146497                          \n",
       "50                                           0.133758                          \n",
       "\n",
       "    Percent below poverty level: Some college, associate's degree  \\\n",
       "0                                            0.662921               \n",
       "1                                            0.000000               \n",
       "2                                            0.528090               \n",
       "3                                            0.764045               \n",
       "4                                            0.528090               \n",
       "..                                                ...               \n",
       "46                                           0.189474               \n",
       "47                                           0.315789               \n",
       "48                                           0.652632               \n",
       "49                                           0.231579               \n",
       "50                                           0.242105               \n",
       "\n",
       "    Percent below poverty level: Bachelor's degree or higher  \\\n",
       "0                                            0.500000          \n",
       "1                                            0.100000          \n",
       "2                                            0.833333          \n",
       "3                                            0.466667          \n",
       "4                                            0.833333          \n",
       "..                                                ...          \n",
       "46                                           0.090909          \n",
       "47                                           0.333333          \n",
       "48                                           0.545455          \n",
       "49                                           0.212121          \n",
       "50                                           0.363636          \n",
       "\n",
       "    Percent below poverty level: Employed  \\\n",
       "0                                0.690141   \n",
       "1                                0.098592   \n",
       "2                                0.732394   \n",
       "3                                0.774648   \n",
       "4                                0.591549   \n",
       "..                                    ...   \n",
       "46                               0.245902   \n",
       "47                               0.262295   \n",
       "48                               0.704918   \n",
       "49                               0.426230   \n",
       "50                               0.508197   \n",
       "\n",
       "    Percent below poverty level: Unemployed             States  venceu  \n",
       "0                                  0.804651        Alabama2012       1  \n",
       "1                                  0.116279         Alaska2012       1  \n",
       "2                                  0.725581        Arizona2012       1  \n",
       "3                                  0.846512       Arkansas2012       1  \n",
       "4                                  0.386047     California2012       0  \n",
       "..                                      ...                ...     ...  \n",
       "46                                 0.246377       Virginia2020       0  \n",
       "47                                 0.328502     Washington2020       0  \n",
       "48                                 0.869565  West Virginia2020       1  \n",
       "49                                 0.487923      Wisconsin2020       0  \n",
       "50                                 0.487923        Wyoming2020       1  \n",
       "\n",
       "[153 rows x 32 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([data2012, data2016, data2020])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "venceu\n",
       "1    79\n",
       "0    74\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##quantidade de 0 e 1 na coluna venceu\n",
    "\n",
    "data['venceu'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percent Insurence: Under 19 years</th>\n",
       "      <th>Percent Insurence: 19 to 64 years</th>\n",
       "      <th>Percent Insurence: 65 years and older</th>\n",
       "      <th>Kindergarten</th>\n",
       "      <th>Elementary: grade 1 to grade 4</th>\n",
       "      <th>Elementary: grade 5 to grade 8</th>\n",
       "      <th>High school: grade 9 to grade 12</th>\n",
       "      <th>College, undergraduate</th>\n",
       "      <th>Graduate, professional school</th>\n",
       "      <th>Population enrolled in college or graduate school</th>\n",
       "      <th>...</th>\n",
       "      <th>Some other race alone</th>\n",
       "      <th>Two or more races:</th>\n",
       "      <th>Percent below poverty level: Population for whom poverty status is determined</th>\n",
       "      <th>Percent below poverty level: Less than high school graduate</th>\n",
       "      <th>Percent below poverty level: High school graduate (includes equivalency)</th>\n",
       "      <th>Percent below poverty level: Some college, associate's degree</th>\n",
       "      <th>Percent below poverty level: Bachelor's degree or higher</th>\n",
       "      <th>Percent below poverty level: Employed</th>\n",
       "      <th>Percent below poverty level: Unemployed</th>\n",
       "      <th>venceu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.177632</td>\n",
       "      <td>0.577689</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.485075</td>\n",
       "      <td>0.442029</td>\n",
       "      <td>0.306011</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.087459</td>\n",
       "      <td>0.161739</td>\n",
       "      <td>0.093178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010408</td>\n",
       "      <td>0.037844</td>\n",
       "      <td>0.633803</td>\n",
       "      <td>0.713483</td>\n",
       "      <td>0.489051</td>\n",
       "      <td>0.662921</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.690141</td>\n",
       "      <td>0.804651</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.822368</td>\n",
       "      <td>0.812749</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.485075</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.082508</td>\n",
       "      <td>0.151304</td>\n",
       "      <td>0.099834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.027340</td>\n",
       "      <td>0.007042</td>\n",
       "      <td>0.129213</td>\n",
       "      <td>0.116788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.098592</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.717131</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.186567</td>\n",
       "      <td>0.202899</td>\n",
       "      <td>0.065574</td>\n",
       "      <td>0.096154</td>\n",
       "      <td>0.067657</td>\n",
       "      <td>0.370435</td>\n",
       "      <td>0.111481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085422</td>\n",
       "      <td>0.105849</td>\n",
       "      <td>0.612676</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.562044</td>\n",
       "      <td>0.528090</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.732394</td>\n",
       "      <td>0.725581</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.296053</td>\n",
       "      <td>0.764940</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.134328</td>\n",
       "      <td>0.340580</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.185897</td>\n",
       "      <td>0.056106</td>\n",
       "      <td>0.092174</td>\n",
       "      <td>0.053245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011710</td>\n",
       "      <td>0.027153</td>\n",
       "      <td>0.690141</td>\n",
       "      <td>0.662921</td>\n",
       "      <td>0.547445</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.774648</td>\n",
       "      <td>0.846512</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.427632</td>\n",
       "      <td>0.772908</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.328358</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.213115</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.130363</td>\n",
       "      <td>0.553043</td>\n",
       "      <td>0.188020</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.492958</td>\n",
       "      <td>0.466292</td>\n",
       "      <td>0.503650</td>\n",
       "      <td>0.528090</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.591549</td>\n",
       "      <td>0.386047</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Percent Insurence: Under 19 years  Percent Insurence: 19 to 64 years  \\\n",
       "0                           0.177632                           0.577689   \n",
       "1                           0.822368                           0.812749   \n",
       "2                           0.776316                           0.717131   \n",
       "3                           0.296053                           0.764940   \n",
       "4                           0.427632                           0.772908   \n",
       "\n",
       "   Percent Insurence: 65 years and older  Kindergarten  \\\n",
       "0                               0.055556      0.485075   \n",
       "1                               0.333333      0.485075   \n",
       "2                               0.555556      0.186567   \n",
       "3                               0.111111      0.134328   \n",
       "4                               0.833333      0.328358   \n",
       "\n",
       "   Elementary: grade 1 to grade 4  Elementary: grade 5 to grade 8  \\\n",
       "0                        0.442029                        0.306011   \n",
       "1                        0.500000                        0.180328   \n",
       "2                        0.202899                        0.065574   \n",
       "3                        0.340580                        0.163934   \n",
       "4                        0.260870                        0.213115   \n",
       "\n",
       "   High school: grade 9 to grade 12  College, undergraduate  \\\n",
       "0                          0.365385                0.087459   \n",
       "1                          0.307692                0.082508   \n",
       "2                          0.096154                0.067657   \n",
       "3                          0.185897                0.056106   \n",
       "4                          0.205128                0.130363   \n",
       "\n",
       "   Graduate, professional school  \\\n",
       "0                       0.161739   \n",
       "1                       0.151304   \n",
       "2                       0.370435   \n",
       "3                       0.092174   \n",
       "4                       0.553043   \n",
       "\n",
       "   Population enrolled in college or graduate school  ...  \\\n",
       "0                                           0.093178  ...   \n",
       "1                                           0.099834  ...   \n",
       "2                                           0.111481  ...   \n",
       "3                                           0.053245  ...   \n",
       "4                                           0.188020  ...   \n",
       "\n",
       "   Some other race alone  Two or more races:  \\\n",
       "0               0.010408            0.037844   \n",
       "1               0.001109            0.027340   \n",
       "2               0.085422            0.105849   \n",
       "3               0.011710            0.027153   \n",
       "4               1.000000            1.000000   \n",
       "\n",
       "   Percent below poverty level: Population for whom poverty status is determined  \\\n",
       "0                                           0.633803                               \n",
       "1                                           0.007042                               \n",
       "2                                           0.612676                               \n",
       "3                                           0.690141                               \n",
       "4                                           0.492958                               \n",
       "\n",
       "   Percent below poverty level: Less than high school graduate  \\\n",
       "0                                           0.713483             \n",
       "1                                           0.129213             \n",
       "2                                           0.769663             \n",
       "3                                           0.662921             \n",
       "4                                           0.466292             \n",
       "\n",
       "   Percent below poverty level: High school graduate (includes equivalency)  \\\n",
       "0                                           0.489051                          \n",
       "1                                           0.116788                          \n",
       "2                                           0.562044                          \n",
       "3                                           0.547445                          \n",
       "4                                           0.503650                          \n",
       "\n",
       "   Percent below poverty level: Some college, associate's degree  \\\n",
       "0                                           0.662921               \n",
       "1                                           0.000000               \n",
       "2                                           0.528090               \n",
       "3                                           0.764045               \n",
       "4                                           0.528090               \n",
       "\n",
       "   Percent below poverty level: Bachelor's degree or higher  \\\n",
       "0                                           0.500000          \n",
       "1                                           0.100000          \n",
       "2                                           0.833333          \n",
       "3                                           0.466667          \n",
       "4                                           0.833333          \n",
       "\n",
       "   Percent below poverty level: Employed  \\\n",
       "0                               0.690141   \n",
       "1                               0.098592   \n",
       "2                               0.732394   \n",
       "3                               0.774648   \n",
       "4                               0.591549   \n",
       "\n",
       "   Percent below poverty level: Unemployed  venceu  \n",
       "0                                 0.804651       1  \n",
       "1                                 0.116279       1  \n",
       "2                                 0.725581       1  \n",
       "3                                 0.846512       1  \n",
       "4                                 0.386047       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop('States', axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('venceu', axis=1).values\n",
    "y = data['venceu'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "# # Supondo que X_train e y_train sejam seus dados de treinamento\n",
    "\n",
    "# # Aumentar o número de instâncias com RandomOverSampler\n",
    "# ros = RandomOverSampler(sampling_strategy={0: 2370, 1: 2220}, random_state=42)  # Aumentando para 200 instâncias da classe 1\n",
    "# X_reshaped, y_reshaped = ros.fit_resample(X, y)\n",
    "\n",
    "# # Verificar a distribuição inicial\n",
    "# print(f\"Instâncias antes do RandomOverSampler: {X.shape[0]}\")\n",
    "# print(f\"Instâncias após o RandomOverSampler: {X_reshaped.shape[0]}\")\n",
    "# print(f\"Distribuição das classes após RandomOverSampler: {pd.Series(y_reshaped).value_counts()}\")\n",
    "\n",
    "# # Aplicar SMOTE para aumentar ainda mais as instâncias\n",
    "# # smote = SMOTE(sampling_strategy={0: 23700, 1: 22200}, random_state=42)\n",
    "# # X_smote, y_smote = smote.fit_resample(X_reshaped, y_train_resampled)\n",
    "\n",
    "# # print(f\"Instâncias após o SMOTE: {X_train_smote.shape[0]}\")\n",
    "# # print(f\"Distribuição das classes após SMOTE: {pd.Series(y_train_smote).value_counts()}\")\n",
    "\n",
    "# #####melhor modelo usa 0:7500 e 1:750\n",
    "# ###modelo mais correto usa 0:2370 e 1:2220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Percent Insurence: Under 19 years',\n",
      "       'Percent Insurence: 19 to 64 years', 'Graduate, professional school',\n",
      "       'Population enrolled in college or graduate school',\n",
      "       'Income per Race: White', 'Income per Race: Black or African American',\n",
      "       'Income per Race: Asian', 'Percent below poverty level: Employed'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "selecao = SelectKBest(score_func=chi2, k=8)\n",
    "                      ##5 -> 0.785\n",
    "                      ##8 -> 0.850\n",
    "X_new = selecao.fit_transform(X, y)\n",
    "selecionadas = selecao.get_support(indices=True)\n",
    "colunas_selecionadas = data.columns[selecionadas]\n",
    "print(colunas_selecionadas)\n",
    "# colunas_selecionadas = X.columns[selecionadas]\n",
    "# print(colunas_selecionadas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instâncias antes do RandomOverSampler: 153\n",
      "Instâncias após o RandomOverSampler: 45900\n",
      "Distribuição das classes após RandomOverSampler: 0    23700\n",
      "1    22200\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "# Supondo que X_train e y_train sejam seus dados de treinamento\n",
    "\n",
    "# Aumentar o número de instâncias com RandomOverSampler\n",
    "ros = RandomOverSampler(sampling_strategy={0: 23700, 1: 22200}, random_state=42)  # Aumentando para 200 instâncias da classe 1\n",
    "X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Verificar a distribuição inicial\n",
    "print(f\"Instâncias antes do RandomOverSampler: {X.shape[0]}\")\n",
    "print(f\"Instâncias após o RandomOverSampler: {X_train.shape[0]}\")\n",
    "print(f\"Distribuição das classes após RandomOverSampler: {pd.Series(y_train).value_counts()}\")\n",
    "\n",
    "# Aplicar SMOTE para aumentar ainda mais as instâncias\n",
    "# smote = SMOTE(sampling_strategy={0: 23700, 1: 22200}, random_state=42)\n",
    "# X_smote, y_smote = smote.fit_resample(X_reshaped, y_train_resampled)\n",
    "\n",
    "# print(f\"Instâncias após o SMOTE: {X_train_smote.shape[0]}\")\n",
    "# print(f\"Distribuição das classes após SMOTE: {pd.Series(y_train_smote).value_counts()}\")\n",
    "\n",
    "#####melhor modelo usa 0:7500 e 1:750\n",
    "#####modelo mais correto usa 0:2370 e 1:2220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "# # Supondo que X_train e y_train sejam seus dados de treinamento\n",
    "\n",
    "# # Aumentar o número de instâncias com RandomOverSampler\n",
    "# ros = RandomOverSampler(sampling_strategy={0: 23700, 1: 22200}, random_state=42)  # Aumentando para 200 instâncias da classe 1\n",
    "# X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "# X_test_resampled, y_test_resampled = ros.fit_resample(X_test, y_test)\n",
    "\n",
    "# # Verificar a distribuição inicial\n",
    "# print(f\"Instâncias antes do RandomOverSampler: {X_train.shape[0]}\")\n",
    "# print(f\"Instâncias após o RandomOverSampler: {X_train_resampled.shape[0]}\")\n",
    "# print(f\"Distribuição das classes após RandomOverSampler: {pd.Series(y_train_resampled).value_counts()}\")\n",
    "\n",
    "# # Aplicar SMOTE para aumentar ainda mais as instâncias\n",
    "# smote = SMOTE(sampling_strategy={0: 23700, 1: 22200}, random_state=42)\n",
    "# X_train_smote, y_train_smote = smote.fit_resample(X_train_resampled, y_train_resampled)\n",
    "# X_test_smote, y_test_smote = smote.fit_resample(X_test_resampled, y_test_resampled)\n",
    "\n",
    "# print(f\"Instâncias após o SMOTE: {X_train_smote.shape[0]}\")\n",
    "# print(f\"Distribuição das classes após SMOTE: {pd.Series(y_train_smote).value_counts()}\")\n",
    "\n",
    "# #####melhor modelo usa 0:6000 e 1:900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "modelo = Sequential()\n",
    "\n",
    "# Camada de entrada\n",
    "modelo.add(Dense(units=64, activation='relu', input_dim=8))\n",
    "modelo.add(Dropout(0.2))\n",
    "modelo.add(Dense(units=32, activation='relu'))\n",
    "modelo.add(Dropout(0.2))\n",
    "modelo.add(Dense(units=16, activation='relu'))\n",
    "modelo.add(Dropout(0.2))\n",
    "\n",
    "# Camada de saida\n",
    "\n",
    "modelo.add(Dense(units=1, activation='sigmoid'))##classificação por isso sigmoid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8256 - loss: 0.3997 - val_accuracy: 0.9348 - val_loss: 0.2055\n",
      "Epoch 2/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9611 - loss: 0.1069 - val_accuracy: 0.9348 - val_loss: 0.2765\n",
      "Epoch 3/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9887 - loss: 0.0394 - val_accuracy: 0.9130 - val_loss: 0.3664\n",
      "Epoch 4/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9935 - loss: 0.0226 - val_accuracy: 0.9130 - val_loss: 0.5240\n",
      "Epoch 5/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9958 - loss: 0.0162 - val_accuracy: 0.9348 - val_loss: 0.6208\n",
      "Epoch 6/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9956 - loss: 0.0133 - val_accuracy: 0.9348 - val_loss: 0.6947\n",
      "Epoch 7/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9970 - loss: 0.0107 - val_accuracy: 0.9130 - val_loss: 0.7257\n",
      "Epoch 8/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9972 - loss: 0.0099 - val_accuracy: 0.9348 - val_loss: 0.8037\n",
      "Epoch 9/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0082 - val_accuracy: 0.9348 - val_loss: 0.8997\n",
      "Epoch 10/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9971 - loss: 0.0101 - val_accuracy: 0.9130 - val_loss: 0.8923\n",
      "Epoch 11/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9971 - loss: 0.0092 - val_accuracy: 0.9130 - val_loss: 0.8190\n",
      "Epoch 12/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9974 - loss: 0.0096 - val_accuracy: 0.9130 - val_loss: 0.8518\n",
      "Epoch 13/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0071 - val_accuracy: 0.9348 - val_loss: 0.8163\n",
      "Epoch 14/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9977 - loss: 0.0074 - val_accuracy: 0.9130 - val_loss: 1.0374\n",
      "Epoch 15/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9983 - loss: 0.0056 - val_accuracy: 0.9348 - val_loss: 0.8358\n",
      "Epoch 16/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9984 - loss: 0.0065 - val_accuracy: 0.8913 - val_loss: 1.0505\n",
      "Epoch 17/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9976 - loss: 0.0073 - val_accuracy: 0.9348 - val_loss: 0.9120\n",
      "Epoch 18/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0062 - val_accuracy: 0.9348 - val_loss: 0.9214\n",
      "Epoch 19/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9979 - loss: 0.0077 - val_accuracy: 0.9348 - val_loss: 0.9516\n",
      "Epoch 20/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0051 - val_accuracy: 0.9130 - val_loss: 1.0968\n",
      "Epoch 21/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0052 - val_accuracy: 0.9130 - val_loss: 0.8218\n",
      "Epoch 22/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0048 - val_accuracy: 0.9130 - val_loss: 1.2858\n",
      "Epoch 23/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0068 - val_accuracy: 0.9348 - val_loss: 0.8228\n",
      "Epoch 24/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9988 - loss: 0.0046 - val_accuracy: 0.9130 - val_loss: 1.2438\n",
      "Epoch 25/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9975 - loss: 0.0078 - val_accuracy: 0.9130 - val_loss: 1.2230\n",
      "Epoch 26/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9986 - loss: 0.0052 - val_accuracy: 0.8696 - val_loss: 1.3290\n",
      "Epoch 27/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0068 - val_accuracy: 0.9348 - val_loss: 1.0044\n",
      "Epoch 28/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 0.9130 - val_loss: 1.3120\n",
      "Epoch 29/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9992 - loss: 0.0028 - val_accuracy: 0.9130 - val_loss: 1.0555\n",
      "Epoch 30/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9988 - loss: 0.0049 - val_accuracy: 0.9130 - val_loss: 1.1194\n",
      "Epoch 31/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9983 - loss: 0.0057 - val_accuracy: 0.9130 - val_loss: 1.1927\n",
      "Epoch 32/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9988 - loss: 0.0057 - val_accuracy: 0.9348 - val_loss: 1.2157\n",
      "Epoch 33/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9987 - loss: 0.0041 - val_accuracy: 0.9130 - val_loss: 1.1571\n",
      "Epoch 34/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0038 - val_accuracy: 0.9348 - val_loss: 1.0937\n",
      "Epoch 35/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0027 - val_accuracy: 0.9348 - val_loss: 1.6881\n",
      "Epoch 36/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0051 - val_accuracy: 0.9130 - val_loss: 1.5858\n",
      "Epoch 37/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0056 - val_accuracy: 0.9348 - val_loss: 1.2784\n",
      "Epoch 38/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9993 - loss: 0.0025 - val_accuracy: 0.9348 - val_loss: 1.2605\n",
      "Epoch 39/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9979 - loss: 0.0061 - val_accuracy: 0.9348 - val_loss: 1.0751\n",
      "Epoch 40/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9981 - loss: 0.0051 - val_accuracy: 0.9130 - val_loss: 1.6479\n",
      "Epoch 41/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0042 - val_accuracy: 0.9130 - val_loss: 1.3107\n",
      "Epoch 42/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9978 - loss: 0.0074 - val_accuracy: 0.8913 - val_loss: 1.6471\n",
      "Epoch 43/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9991 - loss: 0.0038 - val_accuracy: 0.9348 - val_loss: 1.2272\n",
      "Epoch 44/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0035 - val_accuracy: 0.9348 - val_loss: 1.3887\n",
      "Epoch 45/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9985 - loss: 0.0048 - val_accuracy: 0.8913 - val_loss: 1.5187\n",
      "Epoch 46/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9992 - loss: 0.0028 - val_accuracy: 0.8913 - val_loss: 1.3538\n",
      "Epoch 47/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9988 - loss: 0.0045 - val_accuracy: 0.8913 - val_loss: 1.5699\n",
      "Epoch 48/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9985 - loss: 0.0047 - val_accuracy: 0.8913 - val_loss: 1.4728\n",
      "Epoch 49/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9981 - loss: 0.0057 - val_accuracy: 0.9565 - val_loss: 1.9482\n",
      "Epoch 50/50\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0043 - val_accuracy: 0.9130 - val_loss: 1.8329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x23753230a70>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "modelo.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 441 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002374D4B7600> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsao = modelo.predict(X_test)\n",
    "\n",
    "for i in range(len(previsao)):\n",
    "    if previsao[i] >= 0.5:\n",
    "        previsao[i] = 1\n",
    "    else:\n",
    "        previsao[i] = 0\n",
    "previsao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DEMOCRATA',\n",
       " 'DEMOCRATA',\n",
       " 'REPUBLICANO',\n",
       " 'REPUBLICANO',\n",
       " 'REPUBLICANO',\n",
       " 'DEMOCRATA',\n",
       " 'REPUBLICANO',\n",
       " 'REPUBLICANO',\n",
       " 'DEMOCRATA',\n",
       " 'REPUBLICANO',\n",
       " 'REPUBLICANO',\n",
       " 'DEMOCRATA',\n",
       " 'DEMOCRATA',\n",
       " 'DEMOCRATA',\n",
       " 'DEMOCRATA',\n",
       " 'DEMOCRATA',\n",
       " 'REPUBLICANO',\n",
       " 'DEMOCRATA',\n",
       " 'DEMOCRATA',\n",
       " 'REPUBLICANO',\n",
       " 'DEMOCRATA',\n",
       " 'REPUBLICANO',\n",
       " 'DEMOCRATA',\n",
       " 'DEMOCRATA',\n",
       " 'REPUBLICANO',\n",
       " 'REPUBLICANO',\n",
       " 'DEMOCRATA',\n",
       " 'REPUBLICANO',\n",
       " 'DEMOCRATA',\n",
       " 'DEMOCRATA',\n",
       " 'REPUBLICANO',\n",
       " 'DEMOCRATA',\n",
       " 'DEMOCRATA',\n",
       " 'REPUBLICANO',\n",
       " 'REPUBLICANO',\n",
       " 'DEMOCRATA',\n",
       " 'REPUBLICANO',\n",
       " 'REPUBLICANO',\n",
       " 'REPUBLICANO',\n",
       " 'DEMOCRATA',\n",
       " 'REPUBLICANO',\n",
       " 'REPUBLICANO',\n",
       " 'DEMOCRATA',\n",
       " 'DEMOCRATA',\n",
       " 'REPUBLICANO',\n",
       " 'REPUBLICANO']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsao_ref = [\"DEMOCRATA\" if x == 1 else \"REPUBLICANO\" for x in previsao]\n",
    "previsao_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia:  0.9130434782608695\n",
      "Precision:  0.9130434782608695\n",
      "Recall:  0.9130434782608695\n",
      "F1:  0.9130434782608695\n",
      "Precision Score:  0.9130434782608695\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[21  2]\n",
      " [ 2 21]]\n",
      "\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        23\n",
      "           1       0.91      0.91      0.91        23\n",
      "\n",
      "    accuracy                           0.91        46\n",
      "   macro avg       0.91      0.91      0.91        46\n",
      "weighted avg       0.91      0.91      0.91        46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gerando métricas\n",
    "print(\"Acurácia: \", accuracy_score(y_test, previsao))\n",
    "print(\"Precision: \", precision_score(y_test, previsao))\n",
    "print(\"Recall: \", recall_score(y_test, previsao))\n",
    "print(\"F1: \", f1_score(y_test, previsao))\n",
    "print(\"Precision Score: \", precision_score(y_test, previsao))\n",
    "print(\"\\n\")\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, previsao))\n",
    "print(\"\\n\")\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, previsao))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['REPUBLICANO',\n",
       " 'REPUBLICANO',\n",
       " 'REPUBLICANO',\n",
       " 'REPUBLICANO',\n",
       " 'REPUBLICANO',\n",
       " 'DEMOCRATA',\n",
       " 'REPUBLICANO',\n",
       " 'REPUBLICANO',\n",
       " 'DEMOCRATA',\n",
       " 'REPUBLICANO',\n",
       " 'REPUBLICANO',\n",
       " 'DEMOCRATA',\n",
       " 'DEMOCRATA',\n",
       " 'REPUBLICANO',\n",
       " 'DEMOCRATA',\n",
       " 'DEMOCRATA',\n",
       " 'REPUBLICANO',\n",
       " 'DEMOCRATA',\n",
       " 'DEMOCRATA',\n",
       " 'REPUBLICANO',\n",
       " 'DEMOCRATA',\n",
       " 'REPUBLICANO',\n",
       " 'DEMOCRATA',\n",
       " 'REPUBLICANO',\n",
       " 'REPUBLICANO',\n",
       " 'REPUBLICANO',\n",
       " 'DEMOCRATA',\n",
       " 'REPUBLICANO',\n",
       " 'REPUBLICANO',\n",
       " 'DEMOCRATA',\n",
       " 'REPUBLICANO',\n",
       " 'DEMOCRATA',\n",
       " 'REPUBLICANO',\n",
       " 'REPUBLICANO',\n",
       " 'REPUBLICANO',\n",
       " 'REPUBLICANO',\n",
       " 'REPUBLICANO',\n",
       " 'REPUBLICANO',\n",
       " 'REPUBLICANO',\n",
       " 'REPUBLICANO',\n",
       " 'REPUBLICANO',\n",
       " 'REPUBLICANO',\n",
       " 'DEMOCRATA',\n",
       " 'REPUBLICANO',\n",
       " 'REPUBLICANO',\n",
       " 'REPUBLICANO']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsao = modelo.predict(X_test)\n",
    "previsao\n",
    "previsao_ref = [\"DEMOCRATA\" if x == 1 else \"REPUBLICANO\" for x in previsao]\n",
    "previsao_ref"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
